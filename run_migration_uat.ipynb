{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24ae1af7",
   "metadata": {},
   "source": [
    "## Data Migration: SQL Server to Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b6836fc",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd;\n",
    "import pyodbc\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_values\n",
    "from dotenv import load_dotenv;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30a67eb",
   "metadata": {},
   "source": [
    "## 1. Load credentials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95c6ef4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78f320ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_host = os.getenv(\"SQL_SERVER_HOST\")\n",
    "sql_db   = os.getenv(\"SQL_SERVER_DB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ef42b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL SERVER HOST: localhost\\SQLEXPRESS\n",
      "SQL SERVER DB: TransactionDB_UAT\n"
     ]
    }
   ],
   "source": [
    "print(f\"SQL SERVER HOST: {sql_host}\")\n",
    "print(f\"SQL SERVER DB: {sql_db}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be9cf2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_host = os.getenv(\"POSTGRES_HOST\")\n",
    "pg_port = os.getenv(\"POSTGRES_PORT\")\n",
    "pg_db = os.getenv(\"POSTGRES_DB\")\n",
    "pg_user = os.getenv(\"POSTGRES_USER\")\n",
    "pg_password = os.getenv(\"POSTGRES_PASSWORD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e440b9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POSTGRES HOST: localhost\n",
      "POSTGRES PORT: 5432\n",
      "POSTGRES DB: teste\n",
      "POSTGRES USER: airflow\n",
      "POSTGRES PASSWORD: airflow\n"
     ]
    }
   ],
   "source": [
    "print(f\"POSTGRES HOST: {pg_host}\")\n",
    "print(f\"POSTGRES PORT: {pg_port}\")\n",
    "print(f\"POSTGRES DB: {pg_db}\")\n",
    "print(f\"POSTGRES USER: {pg_user}\")\n",
    "print(f\"POSTGRES PASSWORD: {pg_password}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd53973",
   "metadata": {},
   "source": [
    "## Connect to SQL Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2dd4a085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to SQL Server\n",
      "  Server: localhost\\SQLEXPRESS\n",
      "  Database: TransactionDB_UAT\n"
     ]
    }
   ],
   "source": [
    "print(\"Connecting to SQL Server\")\n",
    "print(f\"  Server: {sql_host}\")\n",
    "print(f\"  Database: {sql_db}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2b837c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SUCCESS] -> Connection to SQL Server now live! \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    sql_conn_string = (\n",
    "        f\"Driver={{ODBC Driver 18 for SQL Server}};\"\n",
    "        f\"SERVER={sql_host};\"\n",
    "        f\"DATABASE={sql_db};\"\n",
    "        f\"Trusted_connection=yes;\"\n",
    "        f\"Encrypt=no;\"\n",
    "    )\n",
    "\n",
    "    sql_conn = pyodbc.connect(sql_conn_string)\n",
    "    sql_cursor = sql_conn.cursor()\n",
    "    print(\"[SUCCESS] -> Connection to SQL Server now live! \")\n",
    "except Exception as e:\n",
    "    print(f\"SQL Server connection failed: {e}\")\n",
    "    print(\"\"\" How to troubleshoot\n",
    "          > 1. Check server name is .env file correct\n",
    "          > 2. Verify SQL Server is running\n",
    "          > 3. Check Windows Authentication is enabled\n",
    "          > 4. If certified is the problem, use Encrypt=no or TrustServerCertificate=yes\n",
    " \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94606d80",
   "metadata": {},
   "source": [
    "## 3. Connect to PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1937c770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to PostgreSQL...\n",
      "  Server: localhost\n",
      "  Database: teste\n"
     ]
    }
   ],
   "source": [
    "print(\"Connecting to PostgreSQL...\")\n",
    "print(f\"  Server: {pg_host}\")\n",
    "print(f\"  Database: {pg_db}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5a8d7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to PostgreSQL\n",
      " version: PostgreSQL 13.23 (Debian 13.23-1.pgdg13+1) on x86_...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    pg_conn= psycopg2.connect(\n",
    "        host=pg_host,\n",
    "        port=pg_port,\n",
    "        database=pg_db,\n",
    "        user=pg_user,\n",
    "        password=pg_password\n",
    "    )\n",
    "\n",
    "    pg_cursor = pg_conn.cursor()\n",
    "    pg_cursor.execute(\"SELECT version();\")\n",
    "\n",
    "    pg_version = pg_cursor.fetchone()[0]\n",
    "    print(\"Connected to PostgreSQL\")\n",
    "    print(f\" version: {pg_version[:50]}...\\n\")\n",
    "except psycopg2.OperationalError as e:\n",
    "      print(f\"Postgres connection failed: {e}\")\n",
    "      print(\"\"\" How to troubleshoot\n",
    "               > 1. Check Postgres is running\n",
    "               > 2. Verify username + password\n",
    "               > 3. Check database exists\n",
    "            \"\"\")\n",
    "\n",
    "except Exception as e:\n",
    "     print(\"Unexpected error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962c940b",
   "metadata": {},
   "source": [
    "## 4. Define the tables to migrate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb8e3c8",
   "metadata": {},
   "source": [
    "### Migration order\n",
    "\n",
    "- Categories (no dependencies)\n",
    "- Suppliers (no dependencies)\n",
    "- Customers (no dependencies)\n",
    "- Products (dependencies on Categories and suppliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81c32f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Categories', 'Suppliers', 'Customers', 'Products']\n"
     ]
    }
   ],
   "source": [
    "tables_to_migrate = ['Categories', 'Suppliers', 'Customers', 'Products']\n",
    "print(tables_to_migrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5d9a249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table to migrate: \n",
      "  1. Categories\n",
      "  2. Suppliers\n",
      "  3. Customers\n",
      "  4. Products\n",
      "\n",
      "Total  no of tables to migrate: 4\n"
     ]
    }
   ],
   "source": [
    "print(\"Table to migrate: \")\n",
    "for i, table in enumerate(tables_to_migrate,1):\n",
    "    print(f\"  {i}. {table}\")\n",
    "\n",
    "total_no_tbls = len(tables_to_migrate)\n",
    "print(f\"\\nTotal  no of tables to migrate: {total_no_tbls}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7509b605",
   "metadata": {},
   "source": [
    "### 5. Run pre-migration checks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ec4a70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      ">>> ROW COUNTS\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\">>> ROW COUNTS\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "311e6e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: 11\n"
     ]
    }
   ],
   "source": [
    "test_query = \"SELECT COUNT(*) AS total_rows FROM Products\"\n",
    "sql_cursor.execute(test_query)\n",
    "\n",
    "count = sql_cursor.fetchone()[0]\n",
    "print(f\"Results: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cc8b7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories                 7 rows\n",
      "Suppliers                 10 rows\n",
      "Customers                  3 rows\n",
      "Products                  11 rows\n",
      "---------------------------------\n",
      "TOTAL                     31 rows\n",
      "\n",
      " Baseline captured! \n"
     ]
    }
   ],
   "source": [
    "baseline_counts = {}\n",
    "\n",
    "try:\n",
    "    for table in tables_to_migrate:\n",
    "        row_count_query = f\"SELECT COUNT(*) AS total_rows FROM {table}\"\n",
    "\n",
    "        # Warning: Do not input SQL queries with f-strings in production (this is just for the tutorial)\n",
    "        # Example\n",
    "        ## table = \"users; DROP TABLE users; --\"\n",
    "        ## query = f\"SELECT COUNT(*) FROM {table}\"\n",
    "\n",
    "        sql_cursor.execute(row_count_query)\n",
    "        count = sql_cursor.fetchone()[0]\n",
    "\n",
    "        baseline_counts[table]= count\n",
    "        print(f\"{table:15} {count:>12} rows\")\n",
    "\n",
    "    total_rows = sum(baseline_counts.values())\n",
    "    print(f\"{'-' * 33}\")\n",
    "    print(f\"{'TOTAL':15} {total_rows:>12,} rows\")\n",
    "    print(\"\\n Baseline captured! \")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to get baseline counts: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b643d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      ">>> Check 2: Null COUNTS (CustomerName)\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 50)\n",
    "print(\">>> Check 2: Null COUNTS (CustomerName)\")\n",
    "print(\"=\" * 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c639c1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CHECK 2: NULL CHECKS (CustomerName)\n",
      "[' > 1 customers with Null names...']\n",
      "\n",
      "CHECK 3: Invalid email formats\n",
      "[' > 1 customers with Null names...']\n",
      "\n",
      "CHECK 4: NEGATIVE PRODUCTS PRICES\n",
      "[' > 1 customers with Null names...']\n",
      "\n",
      "CHECK 4: NEGATIVE STOCK QUANTITIES\n",
      "[' > 1 customers with Null names...', ' > 1 products contain negative values...']\n",
      "\n",
      "CHECK 6: ORPHANED FOREIGN KEYS\n",
      "[' > 1 customers with Null names...', ' > 1 products contain negative values...', ' > 11 products with orphaned foreign keys...']\n",
      " > 1 customers with Null names...\n",
      " > 1 products contain negative values...\n",
      " > 11 products with orphaned foreign keys...\n"
     ]
    }
   ],
   "source": [
    "quality_issues = []\n",
    "\n",
    "try:\n",
    "    print(\"\\nCHECK 2: NULL CHECKS (CustomerName)\")\n",
    "    sql_cursor.execute(\"\"\"\n",
    "        SELECT COUNT(*) AS null_count\n",
    "        FROM Customers\n",
    "        WHERE CustomerName IS NULL\n",
    "        \"\"\")\n",
    "    null_names = sql_cursor.fetchone()[0]\n",
    "    if null_names > 0:\n",
    "        quality_issues.append(f\" > {null_names:,} customers with Null names...\")\n",
    "    print(quality_issues)\n",
    "\n",
    "    print(\"\\nCHECK 3: Invalid email formats\")\n",
    "    sql_cursor.execute(\"\"\" SELECT COUNT(*) AS invalid_email_count FROM Customers WHERE email LIKE '@Invalid' \"\"\")\n",
    "    invalid_emails = sql_cursor.fetchone()[0]\n",
    "    if invalid_emails > 0:\n",
    "        quality_issues.append(f\" > {invalid_emails:,} emails with invalid email formats...\")\n",
    "    print(quality_issues)\n",
    "\n",
    "    print(\"\\nCHECK 4: NEGATIVE PRODUCTS PRICES\")\n",
    "    sql_cursor.execute(\"\"\" SELECT COUNT(*) As negative_product_prices_count FROM Products WHERE UnitPrice < 0 \"\"\")\n",
    "    negative_price = sql_cursor.fetchone()[0]\n",
    "    if negative_price > 0:\n",
    "        quality_issues.append(f\" > {negative_price:,} prices contain negative prices...\")\n",
    "    print(quality_issues)\n",
    "\n",
    "    print(\"\\nCHECK 4: NEGATIVE STOCK QUANTITIES\")\n",
    "    sql_cursor.execute(\"\"\"\n",
    "                        SELECT COUNT(*) As negative_stock_quantities_count\n",
    "                       FROM Products\n",
    "                       WHERE StockQuantity < 0\n",
    "                        \"\"\")\n",
    "    negative_stock_quantities = sql_cursor.fetchone()[0]\n",
    "    if negative_stock_quantities > 0:\n",
    "        quality_issues.append(f\" > {negative_stock_quantities:,} products contain negative values...\")\n",
    "    print(quality_issues)\n",
    "\n",
    "    print(\"\\nCHECK 6: ORPHANED FOREIGN KEYS\")\n",
    "    sql_cursor.execute(\"\"\"SELECT COUNT(*) AS orphaned_records FROM Products  prod\n",
    "                        WHERE NOT EXISTS (SELECT 1 FROM Suppliers sup\n",
    "                        WHERE sup.SupplierID = prod.SupplierID)\n",
    "                        \"\"\")\n",
    "    orphaned_fks = sql_cursor.fetchone()[0]\n",
    "    if orphaned_fks > 0:\n",
    "        quality_issues.append(f\" > {orphaned_fks:,} products with orphaned foreign keys...\")\n",
    "    print(quality_issues)\n",
    "\n",
    "    if quality_issues:\n",
    "         for issue in quality_issues:\n",
    "              print(issue)\n",
    "    else:\n",
    "         print(\"No data quality issues identified\")\n",
    "\n",
    "except Exception as e:\n",
    "        print(f\"Error ==>> Unexpected issue {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0143b0e9",
   "metadata": {},
   "source": [
    "### 6. Get table schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fdf646c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "ANALYSE TABLE SCHEMA\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*65)\n",
    "print(\"ANALYSE TABLE SCHEMA\")\n",
    "print(\"=\"*65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ad54ade",
   "metadata": {
    "lines_to_next_cell": 3
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Categories  \n",
      "\n",
      "    COLUMN_NAME DATA_TYPE  CHARACTER_MAXIMUM_LENGTH IS_NULLABLE\n",
      "0    CategoryID       int                       NaN          NO\n",
      "1  CategoryName   varchar                     100.0          NO\n",
      "2   Description   varchar                     255.0          NO\n",
      "=================================================================\n",
      "Suppliers   \n",
      "\n",
      "    COLUMN_NAME DATA_TYPE  CHARACTER_MAXIMUM_LENGTH IS_NULLABLE\n",
      "0    SupplierID       int                       NaN          NO\n",
      "1  SupplierName   varchar                     200.0          NO\n",
      "2   ContactName   varchar                     150.0         YES\n",
      "3       Country   varchar                     100.0         YES\n",
      "4         Phone   varchar                      50.0         YES\n",
      "=================================================================\n",
      "Customers   \n",
      "\n",
      "    COLUMN_NAME DATA_TYPE  CHARACTER_MAXIMUM_LENGTH IS_NULLABLE\n",
      "0    CustomerID       int                       NaN          NO\n",
      "1  CustomerName   varchar                     150.0         YES\n",
      "2         Email   varchar                     150.0          NO\n",
      "3         Phone   varchar                      50.0         YES\n",
      "4       Country   varchar                     100.0         YES\n",
      "5   CreatedDate  datetime                       NaN          NO\n",
      "6      IsActive       bit                       NaN          NO\n",
      "=================================================================\n",
      "Products    \n",
      "\n",
      "     COLUMN_NAME DATA_TYPE  CHARACTER_MAXIMUM_LENGTH IS_NULLABLE\n",
      "0      ProductID       int                       NaN          NO\n",
      "1    ProductName   varchar                     200.0          NO\n",
      "2     CategoryID       int                       NaN          NO\n",
      "3     SupplierID       int                       NaN          NO\n",
      "4      UnitPrice   decimal                       NaN          NO\n",
      "5  StockQuantity       int                       NaN          NO\n",
      "6    CreatedDate  datetime                       NaN          NO\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amaro.manungu\\AppData\\Local\\Temp\\ipykernel_40880\\658331737.py:14: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  schema_df = pd.read_sql(schema_query,sql_conn,params=(table,))\n",
      "C:\\Users\\amaro.manungu\\AppData\\Local\\Temp\\ipykernel_40880\\658331737.py:14: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  schema_df = pd.read_sql(schema_query,sql_conn,params=(table,))\n",
      "C:\\Users\\amaro.manungu\\AppData\\Local\\Temp\\ipykernel_40880\\658331737.py:14: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  schema_df = pd.read_sql(schema_query,sql_conn,params=(table,))\n",
      "C:\\Users\\amaro.manungu\\AppData\\Local\\Temp\\ipykernel_40880\\658331737.py:14: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  schema_df = pd.read_sql(schema_query,sql_conn,params=(table,))\n"
     ]
    }
   ],
   "source": [
    "table_shema = {}\n",
    "\n",
    "try:\n",
    "    for table in tables_to_migrate:\n",
    "        schema_query = f\"\"\"SELECT\n",
    "                        COLUMN_NAME,\n",
    "                        DATA_TYPE,\n",
    "                        CHARACTER_MAXIMUM_LENGTH,\n",
    "                        IS_NULLABLE\n",
    "                        FROM INFORMATION_SCHEMA.COLUMNS\n",
    "                        WHERE TABLE_NAME = ?\n",
    "                        ORDER BY ORDINAL_POSITION\n",
    "                        \"\"\"\n",
    "        schema_df = pd.read_sql(schema_query,sql_conn,params=(table,))\n",
    "        #schema_df = pd.read_sql(schema_query,sql_conn)\n",
    "        table_shema[table] = schema_df\n",
    "        print(f\"=\"*65)\n",
    "        print(f\"{table:<12}\")\n",
    "        print(f\"\\n{schema_df}\")\n",
    "except Exception as e:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f094e2a",
   "metadata": {},
   "source": [
    "### 7. Define data type mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d50dae2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "type_mapping = {\n",
    "'int': 'INTEGER',\n",
    "'bigint': 'BIGINT',\n",
    "'smallint': 'SMALLINT',\n",
    "'tinyint': 'SMALLINT',\n",
    "'bit': 'BOOLEAN',\n",
    "'decimal': 'NUMERIC',\n",
    "'numeric': 'NUMERIC',\n",
    "'money': 'NUMERIC(19,4)',\n",
    "'smallmoney': 'NUMERIC(10,4)',\n",
    "'float': 'DOUBLE PRECISION',\n",
    "'real': 'REAL',\n",
    "'datetime': 'TIMESTAMP',\n",
    "'datetime2': 'TIMESTAMP',\n",
    "'smalldatetime': 'TIMESTAMP',\n",
    "'date': 'DATE',\n",
    "'time': 'TIME',\n",
    "'char': 'CHAR',\n",
    "'varchar': 'VARCHAR',\n",
    "'nchar': 'CHAR',\n",
    "'nvarchar': 'VARCHAR',\n",
    "'text': 'TEXT',\n",
    "'ntext': 'TEXT'\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1794397a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL to PostgreSQL type mapping\n",
      "\n",
      "  int             --->    INTEGER\n",
      "  bigint          --->    BIGINT\n",
      "  smallint        --->    SMALLINT\n",
      "  tinyint         --->    SMALLINT\n",
      "  bit             --->    BOOLEAN\n",
      "  decimal         --->    NUMERIC\n",
      "  numeric         --->    NUMERIC\n",
      "  money           --->    NUMERIC(19,4)\n",
      "  smallmoney      --->    NUMERIC(10,4)\n",
      "  float           --->    DOUBLE PRECISION\n",
      "  real            --->    REAL\n",
      "  datetime        --->    TIMESTAMP\n",
      "  datetime2       --->    TIMESTAMP\n",
      "  smalldatetime   --->    TIMESTAMP\n",
      "  date            --->    DATE\n",
      "  time            --->    TIME\n",
      "  char            --->    CHAR\n",
      "  varchar         --->    VARCHAR\n",
      "  nchar           --->    CHAR\n",
      "  nvarchar        --->    VARCHAR\n",
      "  text            --->    TEXT\n",
      "  ntext           --->    TEXT\n"
     ]
    }
   ],
   "source": [
    "print(\"SQL to PostgreSQL type mapping\")\n",
    "print()\n",
    "\n",
    "for sql_type,pg_type in list(type_mapping.items()):\n",
    "    print(f\"  {sql_type:15} --->    {pg_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c88eeb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "CREATE TABLES IN POSTGRES\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*65)\n",
    "print(\"CREATE TABLES IN POSTGRES\")\n",
    "print(\"=\"*65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e93d52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categoryid SERIAL PRIMARY KEY,\n",
      "        categoryname VARCHAR,\n",
      "        description VARCHAR\n",
      "supplierid SERIAL PRIMARY KEY,\n",
      "        suppliername VARCHAR,\n",
      "        contactname VARCHAR,\n",
      "        country VARCHAR,\n",
      "        phone VARCHAR\n",
      "customerid SERIAL PRIMARY KEY,\n",
      "        customername VARCHAR,\n",
      "        email VARCHAR,\n",
      "        phone VARCHAR,\n",
      "        country VARCHAR,\n",
      "        createddate TIMESTAMP,\n",
      "        isactive BOOLEAN\n",
      "productid SERIAL PRIMARY KEY,\n",
      "        productname VARCHAR,\n",
      "        categoryid INTEGER,\n",
      "        supplierid INTEGER,\n",
      "        unitprice NUMERIC,\n",
      "        stockquantity INTEGER,\n",
      "        createddate TIMESTAMP\n",
      "\n",
      " + =======================================================\n",
      "[SUCCESS] ---> All tables created successfully!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    for table in tables_to_migrate:\n",
    "        schema = table_shema[table]\n",
    "        pg_table = table.lower()\n",
    "\n",
    "        pg_cursor.execute(f\"DROP TABLE IF EXISTS {pg_table} CASCADE\")\n",
    "        column_definitions = []\n",
    "\n",
    "        for idx,row in schema.iterrows():\n",
    "            col_name = row['COLUMN_NAME'].lower()\n",
    "            sql_type = row['DATA_TYPE']\n",
    "\n",
    "            base_type = sql_type.lower()\n",
    "            pg_type = type_mapping.get(base_type, 'TEXT')\n",
    "\n",
    "            if idx == 0 and col_name.endswith('id')  and 'int' in sql_type.lower():\n",
    "                column_definitions.append(f\"{col_name} SERIAL PRIMARY KEY\")\n",
    "            else:\n",
    "                column_definitions.append(f\"{col_name} {pg_type}\")\n",
    "\n",
    "        column_string = \",\\n        \".join(column_definitions)\n",
    "        create_query = f\"\"\"\n",
    "                        CREATE TABLE {pg_table} ({column_string})\n",
    "                        \"\"\"\n",
    "        print(column_string)\n",
    "        pg_cursor.execute(create_query)\n",
    "        pg_conn.commit()\n",
    "    print(\"\\n + \" + \"=\"*55)\n",
    "    print(\"[SUCCESS] ---> All tables created successfully!\")\n",
    "\n",
    "except psycopg2.Error as e:\n",
    "    print(f\"Postgres experienced an error while creating a table: {e}\")\n",
    "    pg_conn.rollback()\n",
    "    raise\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Unexpected issue: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e4f761",
   "metadata": {},
   "source": [
    "# 9. Test Migration with one table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae302bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "TESTING MIGRATION (SINGLE TABLE)\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*65)\n",
    "print(\"TESTING MIGRATION (SINGLE TABLE)\")\n",
    "print(\"=\"*65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33c3fa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_table = 'Customers'\n",
    "pg_table = test_table.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d731afbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Read from SQL Server...\n",
      "2.  Transforming data types...\n",
      "[SUCCESS] --->> Converted IsActive: BIT ---> BOOLEAN\n",
      "3. Prepare the data for loading\n",
      "  Prepared 3 rows\n",
      "4. Insert data into PostgresSQL...\n",
      "Loaded 3 rows\n",
      "5.  Verifying...\n",
      "[SUCCESS] --> Verification passed: 3 == 3\n",
      "\n",
      " Customers migration test successfully completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amaro.manungu\\AppData\\Local\\Temp\\ipykernel_40880\\3419715060.py:4: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  test_df = pd.read_sql(extract_query,sql_conn)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"1. Read from SQL Server...\")\n",
    "    extract_query = f\"SELECT * FROM {pg_table}\"\n",
    "    test_df = pd.read_sql(extract_query,sql_conn)\n",
    "\n",
    "    print(\"2.  Transforming data types...\")\n",
    "\n",
    "    if 'IsActive' in test_df.columns:\n",
    "        test_df['IsActive'] = test_df['IsActive'].astype('bool')\n",
    "        print(\"[SUCCESS] --->> Converted IsActive: BIT ---> BOOLEAN\")\n",
    "\n",
    "        print(\"3. Prepare the data for loading\")\n",
    "        data_tuples =[tuple(row) for row in test_df.to_numpy()]\n",
    "        columns = [col.lower() for col in test_df.columns]\n",
    "\n",
    "        column_string = ', '.join(columns)\n",
    "        placeholders = ', '.join(['%'] * len(columns))\n",
    "\n",
    "        insert_query = f\"\"\"\n",
    "                        INSERT INTO {pg_table} ({column_string})\n",
    "                        VALUES %s\n",
    "                        \"\"\"\n",
    "        print(f\"  Prepared {len(data_tuples):,} rows\")\n",
    "        print(\"4. Insert data into PostgresSQL...\")\n",
    "        execute_values(pg_cursor,insert_query,data_tuples,page_size=1000)\n",
    "        pg_conn.commit()\n",
    "\n",
    "        print(f\"Loaded {len(data_tuples):,} rows\")\n",
    "\n",
    "        print(\"5.  Verifying...\")\n",
    "        pg_cursor.execute(f\"SELECT COUNT(*) AS total_rows FROM {pg_table}\")\n",
    "        pg_count =pg_cursor.fetchone()[0]\n",
    "\n",
    "        sql_count = baseline_counts[test_table]\n",
    "\n",
    "        if pg_count == sql_count:\n",
    "            print(f\"[SUCCESS] --> Verification passed: {pg_count:,} == {sql_count:,}\")\n",
    "        else:\n",
    "            print(f\"[FAILED] --> Count mismatch: {pg_count:,} != {sql_count:,}\")\n",
    "\n",
    "        print(f\"\\n {test_table} migration test successfully completed!\")\n",
    "\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    pg_conn.rollback()\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801f1afb",
   "metadata": {},
   "source": [
    "# 10. Migrate remaining tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f15318c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "MIGRATE REMAINING TABLES\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"* 65)\n",
    "print(\"MIGRATE REMAINING TABLES\")\n",
    "print(\"=\"* 65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669eb09a",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "remaining_tables = [t for t in tables_to_migrate if t != 'Customers']\n",
    "\n",
    "for table in remaining_tables:\n",
    "    pg_table = table.lower()\n",
    "\n",
    "    print(f\"Migrating {table} --> {pg_table}...\")\n",
    "\n",
    "    try:\n",
    "        print(\"1. Reading from SQL Server...\")\n",
    "        extract_query = f\"SLEECT * FROM {table}\"\n",
    "        sql_df = pd.read_sql(extract_query,sql_conn)\n",
    "        print(f\"  Read {len(sql_df):,} rows \\n\\n\")\n",
    "\n",
    "        print(\"2.  Preparing data...\")\n",
    "        data_tuples = [tuple(row) for row in sql_df.to_numpy()]\n",
    "        columns = [col.lower() for col in sql_df.columns]\n",
    "        columns_string = ', '.join(columns)\n",
    "\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
